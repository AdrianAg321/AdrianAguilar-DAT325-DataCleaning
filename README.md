# DAT 325 â€“ Data Validation and Cleaning Project  
Southern New Hampshire University  
Author: Adrian Aguilar  

## Project Overview
This project focuses on applying algorithmic and data-driven techniques to identify and correct inconsistencies, missing values, and formatting errors in large datasets. The goal was to improve data quality, integrity, and readiness for analytical processing or database integration.  

## Objectives
- Detect and handle missing or inconsistent values using Python and Pandas  
- Remove duplicates and standardize formatting for data consistency  
- Implement sorting and filtering logic to identify outliers  
- Automate repetitive cleaning tasks through loops and conditional logic  
- Generate validated datasets ready for analysis or storage in databases  

## Tools and Technologies
- Python 3.12  
- Pandas for data manipulation  
- NumPy for numerical computation  
- Jupyter Notebook and HTML output for reporting  
- Visual Studio Code for scripting and debugging  

## Results
The final deliverable includes a clean, validated dataset and an HTML report summarizing data transformations, validation metrics, and detected anomalies. This process demonstrates the use of structured programming and algorithmic efficiency to enhance data reliability.  

## Related Work
This project complements my CS-340 Animal Shelter CRUD Application, where I integrated database operations and data management. Together, these projects showcase my ability to connect data cleaning and backend database development.
